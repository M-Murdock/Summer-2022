{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains some rough preliminary code for checking English -> Greek translations. As of right now, it can only identify individual Greek words which are obviously incorrect. Word lists are pulled from Pharr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installations and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradio [documentation](https://gradio.app/docs/)\n",
    "\n",
    "greek-accentuation [documentation](https://github.com/jtauber/greek-accentuation/blob/master/docs.rst)\n",
    "\n",
    "greek-normalization [documentation](https://github.com/jtauber/greek-normalisation/blob/master/tests.rst)\n",
    "\n",
    "(I'm also using a couple files from [greek-inflexion](https://github.com/jtauber/greek-inflexion/blob/master/README.md))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: typing-extensions in /opt/anaconda3/lib/python3.8/site-packages (4.2.0)\n",
      "Requirement already satisfied: gradio in /opt/anaconda3/lib/python3.8/site-packages (3.0.13)\n",
      "Requirement already satisfied: orjson in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (3.7.2)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (3.3.2)\n",
      "Requirement already satisfied: pandas in /Users/mallard/.local/lib/python3.8/site-packages (from gradio) (1.4.2)\n",
      "Requirement already satisfied: markdown-it-py[linkify,plugins] in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (2.1.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (1.19.2)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (8.0.1)\n",
      "Requirement already satisfied: pycryptodome in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (3.14.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (2.24.0)\n",
      "Requirement already satisfied: Jinja2 in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (2.11.2)\n",
      "Requirement already satisfied: ffmpy in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (0.3.0)\n",
      "Requirement already satisfied: analytics-python in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (1.4.0)\n",
      "Requirement already satisfied: paramiko in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (2.11.0)\n",
      "Requirement already satisfied: pydub in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: uvicorn in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (0.17.6)\n",
      "Requirement already satisfied: fastapi in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (0.78.0)\n",
      "Requirement already satisfied: python-multipart in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (0.0.5)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (3.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->gradio) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->gradio) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->gradio) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->gradio) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->gradio) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.8/site-packages (from pandas->gradio) (2020.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.8/site-packages (from markdown-it-py[linkify,plugins]->gradio) (0.1.1)\n",
      "Requirement already satisfied: linkify-it-py~=1.0; extra == \"linkify\" in /opt/anaconda3/lib/python3.8/site-packages (from markdown-it-py[linkify,plugins]->gradio) (1.0.3)\n",
      "Requirement already satisfied: mdit-py-plugins; extra == \"plugins\" in /opt/anaconda3/lib/python3.8/site-packages (from markdown-it-py[linkify,plugins]->gradio) (0.3.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests->gradio) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests->gradio) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests->gradio) (1.22)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/anaconda3/lib/python3.8/site-packages (from Jinja2->gradio) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.8/site-packages (from analytics-python->gradio) (1.15.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/anaconda3/lib/python3.8/site-packages (from analytics-python->gradio) (1.6)\n",
      "Requirement already satisfied: backoff==1.10.0 in /opt/anaconda3/lib/python3.8/site-packages (from analytics-python->gradio) (1.10.0)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in /opt/anaconda3/lib/python3.8/site-packages (from paramiko->gradio) (3.2.2)\n",
      "Requirement already satisfied: cryptography>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from paramiko->gradio) (3.1.1)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in /opt/anaconda3/lib/python3.8/site-packages (from paramiko->gradio) (1.5.0)\n",
      "Requirement already satisfied: click>=7.0 in /opt/anaconda3/lib/python3.8/site-packages (from uvicorn->gradio) (7.1.2)\n",
      "Requirement already satisfied: asgiref>=3.4.0 in /opt/anaconda3/lib/python3.8/site-packages (from uvicorn->gradio) (3.5.2)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/anaconda3/lib/python3.8/site-packages (from uvicorn->gradio) (0.13.0)\n",
      "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /opt/anaconda3/lib/python3.8/site-packages (from fastapi->gradio) (1.8.2)\n",
      "Requirement already satisfied: starlette==0.19.1 in /opt/anaconda3/lib/python3.8/site-packages (from fastapi->gradio) (0.19.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.8/site-packages (from aiohttp->gradio) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.8/site-packages (from aiohttp->gradio) (1.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.8/site-packages (from aiohttp->gradio) (6.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.8/site-packages (from aiohttp->gradio) (20.3.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/anaconda3/lib/python3.8/site-packages (from aiohttp->gradio) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/anaconda3/lib/python3.8/site-packages (from aiohttp->gradio) (2.0.12)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.8/site-packages (from aiohttp->gradio) (1.2.0)\n",
      "Requirement already satisfied: uc-micro-py in /opt/anaconda3/lib/python3.8/site-packages (from linkify-it-py~=1.0; extra == \"linkify\"->markdown-it-py[linkify,plugins]->gradio) (1.0.1)\n",
      "Requirement already satisfied: cffi>=1.1 in /opt/anaconda3/lib/python3.8/site-packages (from bcrypt>=3.1.3->paramiko->gradio) (1.14.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.8/site-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->fastapi->gradio) (4.2.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/anaconda3/lib/python3.8/site-packages (from starlette==0.19.1->fastapi->gradio) (3.6.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.8/site-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko->gradio) (2.20)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.8/site-packages (from anyio<5,>=3.4.0->starlette==0.19.1->fastapi->gradio) (1.2.0)\n",
      "Requirement already satisfied: greek-accentuation==1.2.0 in /opt/anaconda3/lib/python3.8/site-packages (1.2.0)\n",
      "Requirement already satisfied: greek-normalisation in /opt/anaconda3/lib/python3.8/site-packages (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install typing-extensions --upgrade\n",
    "!pip install gradio\n",
    "!pip install greek-accentuation==1.2.0\n",
    "!pip install greek-normalisation\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import gradio as gr\n",
    "from greek_accentuation.syllabify import *\n",
    "from greek_normalisation.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put the treebank data into dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read in `paradigms.tsv` and `verbs.tsv` (from [here](https://github.com/jtauber/greek-inflexion/tree/master/homer-data)) as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-178-dab219acfad7>:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df1 = pd.read_csv(paradigms, sep=r' +\t*', on_bad_lines='skip', header=0, names=['Lemma', 'Type', 'Inflected'])\n"
     ]
    }
   ],
   "source": [
    "# paradigms.tsv contains all forms from Pharr\n",
    "paradigms = \"lib/paradigms.tsv\"\n",
    "# verbs.tsv contains verbs from Pharr\n",
    "verbs = \"lib/verbs.tsv\"\n",
    "\n",
    "# convert to dataframes\n",
    "df1 = pd.read_csv(paradigms, sep=r' +\t*', on_bad_lines='skip', header=0, names=['Lemma', 'Type', 'Inflected'])\n",
    "df2 = pd.read_csv(verbs, sep='\t', on_bad_lines='skip', header=0, names=['Lemma', 'Type', 'Inflected'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read in `tbankplus.txt` from [here](https://raw.githubusercontent.com/gregorycrane/Homerica/master/tlg0012-tbankplus.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-179-883d359df122>:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df3 = pd.read_csv(tbank, sep=r'\\t', on_bad_lines='skip', header=0, names=['col1', 'col2', 'col3', 'Lemma', 'Inflected', 'col6', 'col7', 'Type', 'col8'])\n"
     ]
    }
   ],
   "source": [
    "# paradigms.tsv contains all forms from Pharr\n",
    "tbank = \"lib/tlg0012-tbankplus.txt\"\n",
    "\n",
    "# convert to dataframe\n",
    "df3 = pd.read_csv(tbank, sep=r'\\t', on_bad_lines='skip', header=0, names=['col1', 'col2', 'col3', 'Lemma', 'Inflected', 'col6', 'col7', 'Type', 'col8'])\n",
    "df3 = df3[['Lemma', 'Type', 'Inflected']]\n",
    "# get a dataframe of the inflected forms\n",
    "inflected_df3 = df3.loc[:, 'Inflected']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- merge the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "λυουσῃς\n"
     ]
    }
   ],
   "source": [
    "# merge the dataframes\n",
    "df = pd.concat([df1, df2, df3])\n",
    "\n",
    "# get a list of all the inflected forms\n",
    "inflected_forms = df.loc[:, 'Inflected'].tolist()\n",
    "\n",
    "# get a list of the lemmas\n",
    "lemmas = df.loc[:, 'Lemma'].tolist()\n",
    "\n",
    "# get a list of all the inflected forms without accents\n",
    "inflected_no_accents = [strip_accents(str(element)) for element in inflected_forms]\n",
    "# print(inflected_no_accents[30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sent = []\n",
    "key_sent = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Clean and format the input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove extraneous spaces, punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the cleaned input\n",
    "def clean(input):\n",
    "    # strip the whitespace and punctuation from the input\n",
    "    input = input.strip()\n",
    "    input = ''.join(letter for letter in input if letter not in string.punctuation)\n",
    "    return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the answer key and user answer into lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts strings to lists, returns nothing\n",
    "def listify(key, input):\n",
    "    global key_sent \n",
    "    key_sent = key.split(\" \")\n",
    "    global input_sent \n",
    "    input_sent = input.split(\" \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Check breathing marks and accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a string of feedback, corrects any errors so that we can proceed\n",
    "def check_breathing_accents(input):\n",
    "    global key_sent\n",
    "    global input_sent\n",
    "    \n",
    "    feedback = ''\n",
    "    for index, word in enumerate(input_sent):\n",
    "        \n",
    "        # check breathing marks\n",
    "        correct = add_necessary_breathing(word)\n",
    "        if correct != word:\n",
    "            feedback += word + ' does not contain the correct breathing marks \\n'\n",
    "            input_sent[index] = correct\n",
    "            word = correct\n",
    "\n",
    "        # check accents\n",
    "        if not word in key_sent:\n",
    "            for key_word in key_sent:\n",
    "                stripped = strip_accents(word)\n",
    "                key_stripped = strip_accents(key_word)\n",
    "                if stripped == key_stripped:\n",
    "                    feedback += word + ' does not contain the correct accents \\n'\n",
    "                    input_sent[index] = key_word\n",
    "            \n",
    "        else:\n",
    "            feedback += word + ' is a valid word \\n'\n",
    "            \n",
    "    return feedback\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Check sentence length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compares the number of words in the key and user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_len():\n",
    "    global key_sent\n",
    "    global input_sent\n",
    "    if len(key_sent) > len(input_sent):\n",
    "        return 'Your sentence may be missing one or more words'\n",
    "    elif len(key_sent) < len(input_sent):\n",
    "        return 'Your sentence may have one or more extraneous words'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Check whether the tenses/numbers match the answer key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the [Iliad treebank](https://github.com/gregorycrane/Homerica/blob/master/tlg0012-tbankplus.txt) to check whether the given word is correct but in an incorrect form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every word inputted:\n",
    "# 1. checks whether the form matches any word in the key precisely (if so, move to the next word)\n",
    "# 2. converts word to lemma, compares against the lemmas of each word in the key (if ther is a match, notify the user)\n",
    "# 3. otherwise, notify the user that the word is invalid\n",
    "\n",
    "def check_tense_number():\n",
    "    feedback = ''\n",
    "    global key_sent \n",
    "    global input_sent\n",
    "\n",
    "    # get the lemmas of all the words in the key\n",
    "    key_lemmas = []\n",
    "    for word in key_sent:\n",
    "        index = inflected_forms.index(word) if word in inflected_forms else None\n",
    "        # get the lemma\n",
    "        key_lemmas.append(lemmas[index])\n",
    "    \n",
    "        \n",
    "    for word in input_sent:\n",
    "        # if the word isn't in the answer key\n",
    "        if not word in key_sent:\n",
    "            # get the lemma index\n",
    "            index = inflected_forms.index(word) if word in inflected_forms else None\n",
    "            # if there is a lemma for the given word\n",
    "            if index != None:\n",
    "                lem = lemmas[index]\n",
    "                if lem in key_lemmas:\n",
    "                    feedback += (word + ' is the correct word, but not the correct form')\n",
    "                else:\n",
    "                    feedback += (word + ' is a valid Greek word, but is not correct in this translation')\n",
    "            else:\n",
    "                feedback += (word + ' could not be found')\n",
    "\n",
    "    \n",
    "    return feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "μῆνιν is a valid word \n",
      "αειδε does not contain the correct breathing marks \n",
      "ἀειδε does not contain the correct accents \n",
      "\n",
      "None\n",
      "θεᾶς is the correct word, but not the correct form\n"
     ]
    }
   ],
   "source": [
    "def test(key, input):\n",
    "    listify(clean(key), clean(input))\n",
    "    print(check_breathing_accents(input))\n",
    "    print(check_len())\n",
    "    print(check_tense_number())\n",
    "    \n",
    "\n",
    "test('μῆνιν ἄειδε θεά', 'μῆνιν αειδε θεᾶς')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Enter your Greek translation in the 'Greek' box and hit submit. Feedback will be displayed in the 'output' box.\n",
    "   \n",
    "    NOTE: I seem to be getting a warning about how I'm reading in the tsv files. But since it doesn't seem to be affecting the program's ability to run, I'm just ignoring it for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7947/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7947/\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x7fd4149b1fa0>, 'http://127.0.0.1:7947/', None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback None(<Task finishe...> result=None>)\n",
      "handle: <Handle>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "TypeError: 'NoneType' object is not callable\n"
     ]
    }
   ],
   "source": [
    "# def check(Greek):\n",
    "#     # remove any whitespace\n",
    "#     cleaned_Greek = Greek.strip()\n",
    "#     if cleaned_Greek != '':\n",
    "#         # store any feedback\n",
    "#         feedback = valid_words(cleaned_Greek)\n",
    "#         return \"%s\" % (feedback)\n",
    "    \n",
    "#     # if the user doesn't enter any text\n",
    "#     return \"please enter text\"\n",
    "\n",
    "# demo = gr.Interface(fn=check, \n",
    "#                     inputs=[gr.Textbox(lines=2, placeholder=\"Enter Greek translation here...\")],\n",
    "#                     outputs=\"text\")\n",
    "\n",
    "# demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
