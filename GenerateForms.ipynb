{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes a list of Crosby Schaeffer verbs (ultimately to be extracted from the csv generated by `GenerateVocabList`) and generates all the forms of each word using the following steps:\n",
    "1. use Stanza to get the lemmas of each word, store these in a file\n",
    "2. using James Tauber's [greek-inflexion github repo](https://github.com/jtauber/greek-inflexion), follow the steps in [`README-morphgnt.md`](https://github.com/jtauber/greek-inflexion/blob/master/README-morphgnt.md#morphgnt) and use the file created in the last step to generate a list of the forms of each verb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 0: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26992858fad54922a031210a8b33884d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/res…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 10:25:42 INFO: Downloading default packages for language: grc (Ancient_Greek)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 10:25:42 INFO: File exists: /Users/mallard/stanza_resources/grc/default.zip\n",
      "2022-07-27 10:25:43 INFO: Finished downloading models and saved to /Users/mallard/stanza_resources.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.8/site-packages (5.3.1)\r\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "stanza.download('grc') \n",
    "\n",
    "!pip install pyyaml\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: define the list of verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs = ['παύουσ', 'πέμπει', 'γράφω', 'λύω']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: use stanza to get the lemma of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16e863b1fa14cfe8e8eeb4838babb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/res…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 10:17:51 INFO: Loading these models for language: grc (Ancient_Greek):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | proiel  |\n",
      "| pos       | proiel  |\n",
      "| lemma     | proiel  |\n",
      "| depparse  | proiel  |\n",
      "=======================\n",
      "\n",
      "2022-07-27 10:17:51 INFO: Use device: cpu\n",
      "2022-07-27 10:17:51 INFO: Loading: tokenize\n",
      "2022-07-27 10:17:51 INFO: Loading: pos\n",
      "2022-07-27 10:17:52 INFO: Loading: lemma\n",
      "2022-07-27 10:17:52 INFO: Loading: depparse\n",
      "2022-07-27 10:17:52 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['παύον', 'πέμπω', 'πέμπω', 'γράφω', 'λύω']\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline('grc') \n",
    "doc = nlp(\" \".join(verbs))\n",
    "lemmas =[word.lemma for sent in doc.sentences for word in sent.words]\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case=Gen|Gender=Masc|Number=Sing', 'Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act', 'Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act', 'Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin|Voice=Act', None]\n"
     ]
    }
   ],
   "source": [
    "forms = [word.feats for sent in doc.sentences for word in sent.words]\n",
    "print(forms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Store the lemmas in a file (in the same format as the [`*_lexicon.yaml` files](https://github.com/jtauber/greek-inflexion/blob/master/STEM_DATA/dik_lexicon.yaml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'παύον': {'stems': []}}, {'πέμπω': {'stems': []}}, {'πέμπω': {'stems': []}}, {'γράφω': {'stems': []}}, {'λύω': {'stems': []}}]\n"
     ]
    }
   ],
   "source": [
    "file_name = 'lib/cs_lexicon.yaml'\n",
    "\n",
    "dict_file = []\n",
    "for lemma in lemmas: \n",
    "    dict_file.append ({lemma: {'stems':[]}})\n",
    "\n",
    "print(dict_file)\n",
    "\n",
    "# write to yaml file\n",
    "with open(file_name, 'w', encoding=\"utf-8\") as file:\n",
    "    documents = yaml.dump(dict_file, stream=file, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: save file to greek-inflexion/STEM_DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: create new `generate_*_lexicon.py` file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
