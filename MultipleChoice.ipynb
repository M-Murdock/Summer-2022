{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An experimentation with multiple choice questions created using [stanza's](https://stanfordnlp.github.io/stanza/) Ancient [Greek](https://stanfordnlp.github.io/stanza/available_models.html) parser and [jtauber's](https://github.com/jtauber) accentuation rules\n",
    "\n",
    "---\n",
    "## Resources\n",
    "greek-accentuation [documentation](https://github.com/jtauber/greek-accentuation/blob/master/docs.rst)\n",
    "\n",
    "greek-normalization [documentation](https://github.com/jtauber/greek-normalisation/blob/master/tests.rst)\n",
    "\n",
    "---\n",
    "#### Known issues: \n",
    "- Sometimes these exercises are finicky and require restarting the kernel and re-importing greek_accentuation.accentuation\n",
    "- In exercise 4, if a word contains more than one syllable that is spelled the same (as with φιλοσοφια) and the user selects either one of them, Gradio automatically selects the other as well\n",
    "\n",
    "---\n",
    "#### Notes/ Future Updates: \n",
    "- The feedback that Exercise 2 gives is fairly limited because I'm generating the impossible accentuations randomly, rather than according to any rules. Exercise 5 is an attempt to remedy this issue\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stanza in /opt/anaconda3/lib/python3.8/site-packages (1.4.0)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.8/site-packages (from stanza) (4.21.1)\n",
      "Requirement already satisfied: emoji in /opt/anaconda3/lib/python3.8/site-packages (from stanza) (1.7.0)\n",
      "Requirement already satisfied: torch>=1.3.0 in /opt/anaconda3/lib/python3.8/site-packages (from stanza) (1.11.0)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.8/site-packages (from stanza) (4.19.4)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.8/site-packages (from stanza) (2.24.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.8/site-packages (from stanza) (1.19.2)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.8/site-packages (from stanza) (1.15.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.8/site-packages (from stanza) (4.50.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.8/site-packages (from torch>=1.3.0->stanza) (4.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/anaconda3/lib/python3.8/site-packages (from transformers->stanza) (0.7.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.8/site-packages (from transformers->stanza) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.8/site-packages (from transformers->stanza) (2020.10.15)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.8/site-packages (from transformers->stanza) (20.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.8/site-packages (from transformers->stanza) (5.3.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/anaconda3/lib/python3.8/site-packages (from transformers->stanza) (0.12.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests->stanza) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests->stanza) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests->stanza) (1.22)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests->stanza) (2.10)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers->stanza) (2.4.7)\n",
      "Requirement already satisfied: gradio in /opt/anaconda3/lib/python3.8/site-packages (3.0.13)\n",
      "Requirement already satisfied: uvicorn in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (0.17.6)\n",
      "Requirement already satisfied: analytics-python in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (1.4.0)\n",
      "Requirement already satisfied: ffmpy in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (0.3.0)\n",
      "Requirement already satisfied: pandas in /Users/mallard/.local/lib/python3.8/site-packages (from gradio) (1.4.2)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (3.3.2)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (3.8.1)\n",
      "Requirement already satisfied: pycryptodome in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (3.14.1)\n",
      "Requirement already satisfied: pydub in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (1.19.2)\n",
      "Requirement already satisfied: paramiko in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (2.11.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (2.24.0)\n",
      "Requirement already satisfied: python-multipart in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (0.0.5)\n",
      "Requirement already satisfied: markdown-it-py[linkify,plugins] in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (2.1.0)\n",
      "Requirement already satisfied: Jinja2 in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (2.11.2)\n",
      "Requirement already satisfied: orjson in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (3.7.2)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (8.3.1)\n",
      "Requirement already satisfied: fastapi in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (0.78.0)\n",
      "Requirement already satisfied: asgiref>=3.4.0 in /opt/anaconda3/lib/python3.8/site-packages (from uvicorn->gradio) (3.5.2)\n",
      "Requirement already satisfied: click>=7.0 in /opt/anaconda3/lib/python3.8/site-packages (from uvicorn->gradio) (7.1.2)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/anaconda3/lib/python3.8/site-packages (from uvicorn->gradio) (0.13.0)\n",
      "Requirement already satisfied: python-dateutil>2.1 in /opt/anaconda3/lib/python3.8/site-packages (from analytics-python->gradio) (2.8.1)\n",
      "Requirement already satisfied: backoff==1.10.0 in /opt/anaconda3/lib/python3.8/site-packages (from analytics-python->gradio) (1.10.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/anaconda3/lib/python3.8/site-packages (from analytics-python->gradio) (1.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.8/site-packages (from analytics-python->gradio) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.8/site-packages (from pandas->gradio) (2020.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->gradio) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->gradio) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->gradio) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->gradio) (2020.6.20)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.8/site-packages (from aiohttp->gradio) (20.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.8/site-packages (from aiohttp->gradio) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/anaconda3/lib/python3.8/site-packages (from aiohttp->gradio) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.8/site-packages (from aiohttp->gradio) (1.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.8/site-packages (from aiohttp->gradio) (1.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.8/site-packages (from aiohttp->gradio) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/anaconda3/lib/python3.8/site-packages (from aiohttp->gradio) (2.0.12)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in /opt/anaconda3/lib/python3.8/site-packages (from paramiko->gradio) (1.5.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from paramiko->gradio) (3.1.1)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in /opt/anaconda3/lib/python3.8/site-packages (from paramiko->gradio) (3.2.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests->gradio) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests->gradio) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests->gradio) (1.22)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.8/site-packages (from markdown-it-py[linkify,plugins]->gradio) (0.1.1)\n",
      "Requirement already satisfied: linkify-it-py~=1.0; extra == \"linkify\" in /opt/anaconda3/lib/python3.8/site-packages (from markdown-it-py[linkify,plugins]->gradio) (1.0.3)\n",
      "Requirement already satisfied: mdit-py-plugins; extra == \"plugins\" in /opt/anaconda3/lib/python3.8/site-packages (from markdown-it-py[linkify,plugins]->gradio) (0.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/anaconda3/lib/python3.8/site-packages (from Jinja2->gradio) (1.1.1)\n",
      "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /opt/anaconda3/lib/python3.8/site-packages (from fastapi->gradio) (1.8.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: starlette==0.19.1 in /opt/anaconda3/lib/python3.8/site-packages (from fastapi->gradio) (0.19.1)\n",
      "Requirement already satisfied: cffi>=1.4.1 in /opt/anaconda3/lib/python3.8/site-packages (from pynacl>=1.0.1->paramiko->gradio) (1.14.3)\n",
      "Requirement already satisfied: uc-micro-py in /opt/anaconda3/lib/python3.8/site-packages (from linkify-it-py~=1.0; extra == \"linkify\"->markdown-it-py[linkify,plugins]->gradio) (1.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.8/site-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->fastapi->gradio) (4.2.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/anaconda3/lib/python3.8/site-packages (from starlette==0.19.1->fastapi->gradio) (3.6.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.8/site-packages (from cffi>=1.4.1->pynacl>=1.0.1->paramiko->gradio) (2.20)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.8/site-packages (from anyio<5,>=3.4.0->starlette==0.19.1->fastapi->gradio) (1.2.0)\n",
      "Requirement already satisfied: greek-accentuation==1.2.0 in /opt/anaconda3/lib/python3.8/site-packages (1.2.0)\n",
      "Requirement already satisfied: greek-normalisation in /opt/anaconda3/lib/python3.8/site-packages (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install stanza\n",
    "!pip install gradio\n",
    "!pip install greek-accentuation==1.2.0\n",
    "!pip install greek-normalisation\n",
    "\n",
    "from lib.greek_accentuation.greek_accentuation.syllabify import *\n",
    "from lib.greek_accentuation.greek_accentuation.characters import *\n",
    "from lib.greek_accentuation.greek_accentuation.accentuation import *\n",
    "\n",
    "from greek_normalisation.utils import *\n",
    "import enum\n",
    "import gradio as gr\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Generate Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exercise 1: Find the main verb of the sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 0: Get quiz questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the file name here:\n",
    "quiz = 'lib/quiz_questions.txt'\n",
    "\n",
    "# list to hold each line of the file\n",
    "lines = []\n",
    "# list of dictionaries for holding the English answer/ Greek answer\n",
    "exercises = []\n",
    "\n",
    "# Read in the lines from the file\n",
    "with open(quiz) as f:\n",
    "    # create list for holding the exercises\n",
    "    lines = f.readlines()\n",
    "\n",
    "# For each line, use regex to grab the answer and full sentence\n",
    "for sent in lines:\n",
    "    \n",
    "    # Get the greek answer\n",
    "    eng_ans_end = sent.find(':')\n",
    "    english_answer = sent[0:eng_ans_end]\n",
    "\n",
    "    greek_answer = sent[eng_ans_end+1:]\n",
    "    \n",
    "    # Add everything to our list of dictionaries\n",
    "    exercises.append({\"english answer\":english_answer, \"greek answer\":greek_answer})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 1: Parse the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the sentence\n",
    "sentence = \"τῷ στρατηγῷ πέμπει τοὺς ἀδελφούς\" # for testing -- ultimately, we'll read this in from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import stanza\n",
    "\n",
    "# stanza.download('grc') \n",
    "nlp = stanza.Pipeline('grc') \n",
    "doc = nlp(sentence) \n",
    "\n",
    "print(doc)\n",
    "print(doc.entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 2: Find the root of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root = [word for sent in doc.sentences for word in sent.words if word.deprel==\"root\"]\n",
    "print(root)\n",
    "not_roots = [word for sent in doc.sentences for word in sent.words if word.deprel!=\"root\"]\n",
    "print(not_roots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the lemmas for each word\n",
    "print(*[f'word: {word.text+\" \"}\\tlemma: {word.lemma}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 3: Generate other, incorrect answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wrong_answers = random.sample(not_roots, 3)\n",
    "print(wrong_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 4: Put all the potential answers into an array, mix them up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "answers.append(root[0].text)\n",
    "\n",
    "for word in wrong_answers:\n",
    "    answers.append(word.text)\n",
    "    \n",
    "random.shuffle(answers)\n",
    "    \n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 5: Get input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(answer):\n",
    "    if answer == root[0].text:\n",
    "        return \"Correct!\"\n",
    "    return \"Not quite\"\n",
    "\n",
    "demo = gr.Interface(description=\"What is the main verb of the sentence:\", fn=check, inputs=[gr.Radio(answers, label=sentence)], outputs=\"text\")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exercise 2: Accents (identify the word(s) with the impossible accents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: The chosen_words array may vary in length. Ultimately, it would make more sense to have it be a consistent length, even if the number of right/wrong answers changes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 0: Place the words into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the file name here:\n",
    "word_file = 'lib/words.txt'\n",
    "\n",
    "# list to hold each line of the file\n",
    "all_words = '[]'\n",
    "\n",
    "# Read in the lines from the file\n",
    "with open(word_file) as f:\n",
    "    # create list for holding the exercises\n",
    "    all_words = f.read().splitlines() \n",
    "    \n",
    "print(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 1: Randomly choose x number of words from the list. (These are the words which will be in the question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define x here \n",
    "x = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly generate x number of words\n",
    "chosen_words = random.sample(all_words, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 2: Randomly split the array into two parts (correct and incorrect answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divider = random.randint(0, x)\n",
    "correct_words = chosen_words[:divider]\n",
    "incorrect_words = chosen_words[divider:]\n",
    "\n",
    "print(incorrect_words)\n",
    "print(correct_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 3: For each 'incorrect' word,\n",
    "    1. make a list of all the potentially correct accentuations\n",
    "    2. strip the accents\n",
    "    3. randomly insert accents\n",
    "    4. check whether the accents are valid (whether they're in the list)\n",
    "    5. try to replace the word with a version containing invalid accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = []\n",
    "\n",
    "# loop through each of the words for which we will assign incorrect accents\n",
    "for w_index in range(0, len(incorrect_words)):\n",
    "    \n",
    "    # get the word, break it into syllables\n",
    "    w = incorrect_words[w_index]\n",
    "    s = syllabify(strip_accents(w))\n",
    "    \n",
    "    # types of accents\n",
    "    types = [Accentuation.OXYTONE, Accentuation.PERISPOMENON, Accentuation.PAROXYTONE, Accentuation.PROPERISPOMENON, Accentuation.PROPAROXYTONE]\n",
    "    \n",
    "    # make a list of *potentially correct* accentuations for that word\n",
    "    possible_correct = []\n",
    "    for a in possible_accentuations(s):\n",
    "        possible_correct.append(add_accentuation(s, a))\n",
    "\n",
    "    # make a list of *all* the possible accentuations for that word\n",
    "    all_accents = []\n",
    "    for acc_type in types:\n",
    "        try:\n",
    "            all_accents.append(add_accentuation(s, acc_type))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # find the difference between the two lists\n",
    "    possible_incorrect = list(set(all_accents)-set(possible_correct))\n",
    "    \n",
    "    # if there are no incorrect answers, remove the word from incorrect_words\n",
    "    if len(possible_incorrect) == 0:\n",
    "        to_remove.append(w)\n",
    "        \n",
    "    # if there is an incorrect answer, add it to the list\n",
    "    elif len(possible_incorrect) == 0:\n",
    "        incorrect_words[w_index] = possible_incorrect[0]\n",
    "        \n",
    "    # if there is ore than one incorrect answer, randomly pick one\n",
    "    else:\n",
    "        incorrect_words[w_index] = random.choice(possible_incorrect)\n",
    "    \n",
    "    print(possible_correct)\n",
    "    print(all_accents)\n",
    "\n",
    "for r in to_remove:\n",
    "    incorrect_words.remove(r)\n",
    "    \n",
    "print(incorrect_words)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 4: shuffle the array of answers (both correct and incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinsert the incorrect answers into the original array\n",
    "chosen_words = correct_words[:] + incorrect_words[:]\n",
    "\n",
    "# shuffle the array\n",
    "random.shuffle(chosen_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 5: Get input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check2(answer):\n",
    "    if not len(answer) == len(incorrect_words):\n",
    "        return \"You have either selected too many or too few answers\"\n",
    "        \n",
    "    for i in answer:\n",
    "        if i not in incorrect_words:\n",
    "            return \"One or more of your answers is incorrect\"\n",
    "        \n",
    "    return \"Correct!\"\n",
    "\n",
    "demo2 = gr.Interface(description=\"Which of the following words contain impossible accents?:\", fn=check2, inputs=[gr.CheckboxGroup(choices=chosen_words, type=\"value\")], outputs=\"text\")\n",
    "\n",
    "demo2.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exercise 3: Identifying Syllables\n",
    "The user is asked to identify the antepenult, penult, or ultima of a given word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 0: Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# cognates.tsv contains a list of cognates \n",
    "cognates_csv = \"lib/cognates.csv\"\n",
    "\n",
    "# convert to dataframes\n",
    "cognates_df = pd.read_fwf(cognates_csv, header=None, names=[\"word\"])\n",
    "\n",
    "cognates_list = cognates_df['word'].tolist()\n",
    "\n",
    "# print(cognates_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 1: Choose a greek word from our list randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_word = random.choice(cognates_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 2: Break the word into syllables (using jtauber's greek-accentuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = syllabify(cur_word)\n",
    "# print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 3: Randomly choose either the antepenult, penult, or ultima of the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terminology = ['antepenult', 'penult', 'ultima']\n",
    "cur_terminology = random.choice(terminology)\n",
    "print(cur_terminology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 4: Based on this random choice, determine the antepenult, penult, or ultima of the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_correct_answer = ''\n",
    "\n",
    "if cur_terminology == 'antepenult':\n",
    "    cur_correct_answer = antepenult(cur_word)\n",
    "elif cur_terminology == 'penult':\n",
    "    cur_correct_answer = penult(cur_word)\n",
    "else:\n",
    "    cur_correct_answer = ultima(cur_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 5: Ask the user to choose (multiple choice) the antepenult, penult, or ultima of the word (as determined above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "none_above = \"None of the above\"\n",
    "def check3(answer):\n",
    "    # if the current word does not have an antepenult/penult/ultima\n",
    "    if cur_correct_answer not in s:\n",
    "        if answer == none_above:\n",
    "            return \"Correct!\"\n",
    "    else:\n",
    "        if answer == cur_correct_answer:\n",
    "            return \"Correct!\"\n",
    "    return \"Incorrect\"\n",
    "\n",
    "if none_above not in s:\n",
    "    s.append(none_above)\n",
    "desc = \"What is the \" + cur_terminology + \" of the word \" + cur_word + \"?\"\n",
    "\n",
    "demo3 = gr.Interface(description=desc, fn=check3, inputs=[gr.Radio(choices=s, type=\"value\", label='')], outputs=\"text\")\n",
    "\n",
    "demo3.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exercise 4: Accents (Rules)\n",
    "Ask questions abouve which syllables particular accents are allowed to reside within"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 0: Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cognates.csv contains a list of cognates\n",
    "cognates_csv = \"lib/cognates.csv\"\n",
    "\n",
    "# convert to dataframes\n",
    "cognates_df = pd.read_fwf(cognates_csv, header=None, names=[\"word\"])\n",
    "\n",
    "cognates_list = cognates_df['word'].tolist()\n",
    "\n",
    "# print(cognates_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 1: Randomly choose a word, break it into syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_word = random.choice(cognates_list)\n",
    "s = syllabify(strip_accents(cur_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 2: Randomly choose acute, circumflex, or grave. Identify the penult, ultima, and antepenult of the word & the possible locations of acutes/circumflexes/graves according to the following rules - \n",
    "    \n",
    "    1. circumflex can only be on long penult or ultima\n",
    "    2. accented penult must have a circumflex if it is long and the ultima is short\n",
    "    3. otherwise, penult has an acute\n",
    "    4. an accented ultima CAN have a circumflex if it is long \n",
    "    5. an acute on the ultima becomes a grave if another word follows immediately (e.g. if there is not a comma or a full stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "σο\n",
      "φί\n",
      "α\n",
      "grave\n",
      "another word follows immediately\n",
      "['none of the above']\n"
     ]
    }
   ],
   "source": [
    "from lib.greek_accentuation.greek_accentuation.accentuation import *\n",
    "\n",
    "# randomly choose whether to quiz on acute, circumflex, or grave\n",
    "accents = ['acute', 'circumflex', 'grave']\n",
    "cur_accent = random.choice(accents)\n",
    "\n",
    "# randomly choose the location of the word within a sentence\n",
    "location = ['another word follows immediately', 'the word is followed by a comma or a full stop']\n",
    "cur_location = random.choice(location)\n",
    "\n",
    "# determine the antepenult, penult, and ultima of the word\n",
    "antepenult = antepenult(cur_word)\n",
    "penult = penult(cur_word)\n",
    "ultima = ultima(cur_word)\n",
    "\n",
    "# identify the possible legal locations of the accent\n",
    "correct_answers = ['none of the above']\n",
    "\n",
    "if cur_accent == 'circumflex': # circumflex can be only on long penult or ultima\n",
    "    if (length(penult) == Length.LONG) and  (length(ultima) == Length.SHORT): # accented penult must have a circumflex if it is long and the ultima is short\n",
    "        correct_answer = [penult]\n",
    "\n",
    "    elif length(ultima) == Length.LONG: # if accented ultima is long, it can have a circumflex\n",
    "        correct_answers = [ultima]\n",
    "        \n",
    "elif cur_accent == 'acute':\n",
    "    if not ((length(penult) == Length.LONG) and  (length(ultima) == Length.SHORT)): #otherwise, penult has an acute\n",
    "        correct_answers = [penult]\n",
    "        \n",
    "elif cur_accent == 'grave':\n",
    "    if location == 'another word follows immediately':\n",
    "        correct_answers = [ultima]\n",
    "\n",
    "print(antepenult)\n",
    "print(penult)\n",
    "print(ultima)\n",
    "print(cur_accent)\n",
    "print(cur_location)\n",
    "print(correct_answers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a type of accent, have the user determine whether the accent goes on the ultima, penult, or antepenult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x7feeb8c82cd0>, 'http://127.0.0.1:7865/', None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback None(<Task finishe...> result=None>)\n",
      "handle: <Handle>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "TypeError: 'NoneType' object is not callable\n"
     ]
    }
   ],
   "source": [
    "def check4(answer):\n",
    "    # incorrect number of answers were selected\n",
    "    if not len(answer) == len(correct_answers):\n",
    "        return \"You have either selected too many or too few answers\"\n",
    "        \n",
    "    for i in answer:\n",
    "        try:\n",
    "            # a syllable before the antepenult was selected\n",
    "            if s.index(i) < s.index(antepenult):\n",
    "                return \"You cannot have an accent before the antepenult\"\n",
    "        except: \n",
    "            pass\n",
    "        # one or more incorrect answers selected\n",
    "        if i not in correct_answers:\n",
    "            return \"One or more of your answers is incorrect\"\n",
    "        \n",
    "    return \"Correct!\"\n",
    "\n",
    "\n",
    "desc4 = \"Is it possible to have a(n) \" + cur_accent + \" in the word \" + strip_accents(cur_word) + \"? Assume that \" + cur_location + \". If it is not possible, select \\'none of the above\\'\"\n",
    "\n",
    "if 'none of the above' not in s:\n",
    "    s.append('none of the above')\n",
    "    \n",
    "\n",
    "demo4 = gr.Interface(description=desc4, fn=check4, inputs=[gr.CheckboxGroup(choices=s, type=\"value\", label='')], outputs=\"text\")\n",
    "\n",
    "demo4.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exercise 5: Accents (identify the versions of a word with impossible accents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 0: Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ἄθεος', 'ἀθλητής', 'ἀθλητικός', 'βῆτα', 'βιβλιογραφία', 'κατάλυσις', 'καταστροφή', 'δημοκρατία', 'διαχρονικός', 'δρᾶμᾰ', 'ἐκκλησιαστικός', 'εὐλογίζω', 'φαντασία', 'γεωγραφία', 'ἥρως', 'ἱστωρία', 'ὑπροκρίτης', 'ἰδιώτης', 'κρύπτων', 'λιθογραφία', 'μόναρχος', 'νεκρόπολις', 'ὤμεγα', 'ὄμικρον', 'φιλοσοφία', 'πρᾶξις', 'ψυχοανάλυσις', 'ῥαψωδία', 'σοφία', 'θησαυρός', 'ὔψιλον', 'ἔψιλον', 'ξενοφοβία', 'ξυλόφωνος', 'ζηλωτής', 'ζῶογραφία']\n"
     ]
    }
   ],
   "source": [
    "# cognates.tsv contains a list of cognates (NOTE: this list is not yet complete)\n",
    "cognates_csv = \"lib/cognates.csv\"\n",
    "\n",
    "# convert to dataframes\n",
    "cognates_df = pd.read_fwf(cognates_csv, header=None, names=[\"word\"])\n",
    "\n",
    "cognates_list = cognates_df['word'].tolist()\n",
    "\n",
    "print(cognates_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 1: Randomly choose a word, find all the possible accentuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "λιθογραφία\n",
      "['λι', 'θο', 'γρα', 'φι', 'α']\n"
     ]
    }
   ],
   "source": [
    "cur_word = random.choice(cognates_list)\n",
    "\n",
    "s = syllabify(strip_accents(cur_word))\n",
    "\n",
    "# make a list of correct accentuations for that word\n",
    "correct = []\n",
    "for a in possible_accentuations(s):\n",
    "    correct.append(add_accentuation(s, a))\n",
    "    \n",
    "print(cur_word)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 2: find impossible accentuations\n",
    "    \n",
    "    For each accentuation rule:\n",
    "     1. break it\n",
    "     2. add the word to the list of impossible accentuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['λιθόγραφια', 'λιθογραφια']\n",
      "['λιθογραφιά', 'λιθογραφιᾶ', 'λιθογραφία', 'λιθογραφῖα', 'λιθογράφια']\n",
      "['No accent can go before the antepenult', 'If it is not true that the penult is long and the ultima is short, the penult must have an acute']\n"
     ]
    }
   ],
   "source": [
    "from lib.greek_accentuation.greek_accentuation.accentuation import *\n",
    "\n",
    "# determine the antepenult, penult, and ultima of the word\n",
    "antepenult = antepenult(cur_word)\n",
    "penult = penult(cur_word)\n",
    "ultima = ultima(cur_word)\n",
    "\n",
    "impossible = []\n",
    "impossible_feedback = []\n",
    "\n",
    "cur_word = strip_accents(cur_word)\n",
    "# Generate incorrect accentuations following these rules:\n",
    "#--------------------------------\n",
    "# 1. put an accent before the antepenult (assuming that there is a syllable before the antepenult)\n",
    "if len(s) > 3:\n",
    "    impossible.append(cur_word.replace(s[-4], syllable_add_accent(s[-4], Accent.ACUTE)))\n",
    "    impossible_feedback.append(\"No accent can go before the antepenult\")\n",
    "    \n",
    "# 2. if the penult is long and the ultima is short, put an acute on the penult\n",
    "if (length(penult) == Length.LONG) and (len(ultima) == Length.SHORT):\n",
    "    impossible.append(cur_word.replace(penult, syllable_add_accent(penult, Accent.ACUTE)))\n",
    "    impossible_feedback.append(\"An accented penult must have a circumflex if it is long and the ultima is short\")\n",
    "    \n",
    "# 3. otherwise, put a circumflex on the penult\n",
    "else:\n",
    "    impossible.append(cur_word.replace(penult, syllable_add_accent(penult, Accent.CIRCUMFLEX)))\n",
    "    impossible_feedback.append(\"If it is not true that the penult is long and the ultima is short, the penult must have an acute\")\n",
    "    \n",
    "# 4. put circumflex over short ultimate\n",
    "if (len(ultima) == Length.SHORT):\n",
    "    impossible.append(cur_word.replace(ultima, syllable_add_accent(ultima, Accent.CIRCUMFLEX)))\n",
    "    impossible_feedback.append(\"an accented ultimate can have a circumflex if it is long\")\n",
    "    \n",
    "print(impossible)\n",
    "print(correct)\n",
    "print(impossible_feedback)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 3: Randomly choose several words from each list, combine them in one big list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['λιθόγραφια', 'λιθογράφια']\n"
     ]
    }
   ],
   "source": [
    "# randomly generate x number of correct, impossible words\n",
    "big_list = random.sample(impossible, random.randrange(0, len(impossible))) + random.sample(correct, random.randrange(1, len(correct)))\n",
    "\n",
    "# shuffle the array\n",
    "random.shuffle(big_list)\n",
    "\n",
    "print(big_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 4: Gradio interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x7feeb8b85ee0>, 'http://127.0.0.1:7864/', None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback None(<Task finishe...> result=None>)\n",
      "handle: <Handle>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "TypeError: 'NoneType' object is not callable\n"
     ]
    }
   ],
   "source": [
    "def check5(answer):\n",
    "    if (len(answer) == 0) and (len(correct) != 0):\n",
    "        return 'Not quite.'\n",
    "    feedback = []\n",
    "    for i in answer:\n",
    "        # one or more incorrect answers selected\n",
    "        if i in impossible:\n",
    "            index = impossible.index(str(i))\n",
    "            feedback.append(impossible_feedback[index] + '\\n')\n",
    "    \n",
    "    if len(feedback) == 0:\n",
    "        return 'Correct!'\n",
    "    return ''.join(feedback)\n",
    "\n",
    "\n",
    "\n",
    "desc5 = \"Identify all of the possible accents\"\n",
    "\n",
    "    \n",
    "\n",
    "demo5 = gr.Interface(description=desc5, fn=check5, inputs=[gr.CheckboxGroup(choices=big_list, type=\"value\", label='Select all of the correct answers. If none of the answers are correct, just hit \\'submit\\'')], outputs=\"text\")\n",
    "\n",
    "demo5.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
