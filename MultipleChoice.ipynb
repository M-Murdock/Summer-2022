{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An experimentation with multiple choice questions created using [stanza's](https://stanfordnlp.github.io/stanza/) Ancient [Greek](https://stanfordnlp.github.io/stanza/available_models.html) parser and [jtauber's](https://github.com/jtauber) accentuation rules\n",
    "\n",
    "---\n",
    "## Resources\n",
    "greek-accentuation [documentation](https://github.com/jtauber/greek-accentuation/blob/master/docs.rst)\n",
    "\n",
    "greek-normalization [documentation](https://github.com/jtauber/greek-normalisation/blob/master/tests.rst)\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stanza in /opt/anaconda3/lib/python3.8/site-packages (1.4.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.8/site-packages (from stanza) (2.24.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.8/site-packages (from stanza) (1.19.2)\n",
      "Requirement already satisfied: torch>=1.3.0 in /opt/anaconda3/lib/python3.8/site-packages (from stanza) (1.11.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.8/site-packages (from stanza) (4.50.2)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.8/site-packages (from stanza) (1.15.0)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.8/site-packages (from stanza) (4.19.4)\n",
      "Requirement already satisfied: emoji in /opt/anaconda3/lib/python3.8/site-packages (from stanza) (1.7.0)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.8/site-packages (from stanza) (4.21.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests->stanza) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests->stanza) (1.22)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests->stanza) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests->stanza) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.8/site-packages (from torch>=1.3.0->stanza) (4.2.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/anaconda3/lib/python3.8/site-packages (from transformers->stanza) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.8/site-packages (from transformers->stanza) (5.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.8/site-packages (from transformers->stanza) (20.4)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.8/site-packages (from transformers->stanza) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/anaconda3/lib/python3.8/site-packages (from transformers->stanza) (0.7.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.8/site-packages (from transformers->stanza) (2020.10.15)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers->stanza) (2.4.7)\n",
      "Requirement already satisfied: gradio in /opt/anaconda3/lib/python3.8/site-packages (3.0.13)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (3.3.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (1.19.2)\n",
      "Requirement already satisfied: ffmpy in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (0.3.0)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (3.8.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (2.24.0)\n",
      "Requirement already satisfied: python-multipart in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (0.0.5)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (8.3.1)\n",
      "Requirement already satisfied: uvicorn in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (0.17.6)\n",
      "Requirement already satisfied: orjson in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (3.7.2)\n",
      "Requirement already satisfied: pycryptodome in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (3.14.1)\n",
      "Requirement already satisfied: paramiko in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (2.11.0)\n",
      "Requirement already satisfied: fastapi in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (0.78.0)\n",
      "Requirement already satisfied: analytics-python in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (1.4.0)\n",
      "Requirement already satisfied: pydub in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: pandas in /Users/mallard/.local/lib/python3.8/site-packages (from gradio) (1.4.2)\n",
      "Requirement already satisfied: markdown-it-py[linkify,plugins] in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (2.1.0)\n",
      "Requirement already satisfied: Jinja2 in /opt/anaconda3/lib/python3.8/site-packages (from gradio) (2.11.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->gradio) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->gradio) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->gradio) (2.8.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->gradio) (2020.6.20)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->gradio) (0.10.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.8/site-packages (from aiohttp->gradio) (1.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.8/site-packages (from aiohttp->gradio) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.8/site-packages (from aiohttp->gradio) (20.3.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/anaconda3/lib/python3.8/site-packages (from aiohttp->gradio) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/anaconda3/lib/python3.8/site-packages (from aiohttp->gradio) (2.0.12)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.8/site-packages (from aiohttp->gradio) (1.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.8/site-packages (from aiohttp->gradio) (6.0.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests->gradio) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests->gradio) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests->gradio) (1.22)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/anaconda3/lib/python3.8/site-packages (from python-multipart->gradio) (1.15.0)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/anaconda3/lib/python3.8/site-packages (from uvicorn->gradio) (0.13.0)\n",
      "Requirement already satisfied: click>=7.0 in /opt/anaconda3/lib/python3.8/site-packages (from uvicorn->gradio) (7.1.2)\n",
      "Requirement already satisfied: asgiref>=3.4.0 in /opt/anaconda3/lib/python3.8/site-packages (from uvicorn->gradio) (3.5.2)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in /opt/anaconda3/lib/python3.8/site-packages (from paramiko->gradio) (1.5.0)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in /opt/anaconda3/lib/python3.8/site-packages (from paramiko->gradio) (3.2.2)\n",
      "Requirement already satisfied: cryptography>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from paramiko->gradio) (3.1.1)\n",
      "Requirement already satisfied: starlette==0.19.1 in /opt/anaconda3/lib/python3.8/site-packages (from fastapi->gradio) (0.19.1)\n",
      "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /opt/anaconda3/lib/python3.8/site-packages (from fastapi->gradio) (1.8.2)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/anaconda3/lib/python3.8/site-packages (from analytics-python->gradio) (1.6)\n",
      "Requirement already satisfied: backoff==1.10.0 in /opt/anaconda3/lib/python3.8/site-packages (from analytics-python->gradio) (1.10.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.8/site-packages (from pandas->gradio) (2020.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.8/site-packages (from markdown-it-py[linkify,plugins]->gradio) (0.1.1)\n",
      "Requirement already satisfied: linkify-it-py~=1.0; extra == \"linkify\" in /opt/anaconda3/lib/python3.8/site-packages (from markdown-it-py[linkify,plugins]->gradio) (1.0.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mdit-py-plugins; extra == \"plugins\" in /opt/anaconda3/lib/python3.8/site-packages (from markdown-it-py[linkify,plugins]->gradio) (0.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/anaconda3/lib/python3.8/site-packages (from Jinja2->gradio) (1.1.1)\n",
      "Requirement already satisfied: cffi>=1.4.1 in /opt/anaconda3/lib/python3.8/site-packages (from pynacl>=1.0.1->paramiko->gradio) (1.14.3)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/anaconda3/lib/python3.8/site-packages (from starlette==0.19.1->fastapi->gradio) (3.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0; python_version < \"3.10\" in /opt/anaconda3/lib/python3.8/site-packages (from starlette==0.19.1->fastapi->gradio) (4.2.0)\n",
      "Requirement already satisfied: uc-micro-py in /opt/anaconda3/lib/python3.8/site-packages (from linkify-it-py~=1.0; extra == \"linkify\"->markdown-it-py[linkify,plugins]->gradio) (1.0.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.8/site-packages (from cffi>=1.4.1->pynacl>=1.0.1->paramiko->gradio) (2.20)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.8/site-packages (from anyio<5,>=3.4.0->starlette==0.19.1->fastapi->gradio) (1.2.0)\n",
      "Requirement already satisfied: greek-accentuation==1.2.0 in /opt/anaconda3/lib/python3.8/site-packages (1.2.0)\n",
      "Requirement already satisfied: greek-normalisation in /opt/anaconda3/lib/python3.8/site-packages (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install stanza\n",
    "!pip install gradio\n",
    "!pip install greek-accentuation==1.2.0\n",
    "!pip install greek-normalisation\n",
    "from greek_accentuation.syllabify import *\n",
    "from greek_accentuation.characters import *\n",
    "# from greek_accentuation.accentuation import * \n",
    "from lib.greek_accentuation.greek_accentuation.accentuation import *\n",
    "from greek_normalisation.utils import *\n",
    "import gradio as gr\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Generate Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exercise 1: Find the main verb of the sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 0: Get quiz questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the file name here:\n",
    "quiz = 'lib/quiz_questions.txt'\n",
    "\n",
    "# list to hold each line of the file\n",
    "lines = []\n",
    "# list of dictionaries for holding the English answer/ Greek answer\n",
    "exercises = []\n",
    "\n",
    "# Read in the lines from the file\n",
    "with open(quiz) as f:\n",
    "    # create list for holding the exercises\n",
    "    lines = f.readlines()\n",
    "\n",
    "# For each line, use regex to grab the answer and full sentence\n",
    "for sent in lines:\n",
    "    \n",
    "    # Get the greek answer\n",
    "    eng_ans_end = sent.find(':')\n",
    "    english_answer = sent[0:eng_ans_end]\n",
    "\n",
    "    greek_answer = sent[eng_ans_end+1:]\n",
    "    \n",
    "    # Add everything to our list of dictionaries\n",
    "    exercises.append({\"english answer\":english_answer, \"greek answer\":greek_answer})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 1: Parse the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the sentence\n",
    "sentence = \"τῷ στρατηγῷ πέμπει τοὺς ἀδελφούς\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b578f8d96b6944a49cbd00179f08ab10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/res…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 13:56:38 INFO: Loading these models for language: grc (Ancient_Greek):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | proiel  |\n",
      "| pos       | proiel  |\n",
      "| lemma     | proiel  |\n",
      "| depparse  | proiel  |\n",
      "=======================\n",
      "\n",
      "2022-06-28 13:56:38 INFO: Use device: cpu\n",
      "2022-06-28 13:56:38 INFO: Loading: tokenize\n",
      "2022-06-28 13:56:38 INFO: Loading: pos\n",
      "2022-06-28 13:56:38 INFO: Loading: lemma\n",
      "2022-06-28 13:56:38 INFO: Loading: depparse\n",
      "2022-06-28 13:56:38 INFO: Done loading processors!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sentence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f14b03a73287>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# stanza.download('grc')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstanza\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'grc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentence' is not defined"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "# stanza.download('grc') \n",
    "nlp = stanza.Pipeline('grc') \n",
    "doc = nlp(sentence) \n",
    "\n",
    "print(doc)\n",
    "print(doc.entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 2: Find the root of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-61591be3f4c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprel\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"root\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnot_roots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprel\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m\"root\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_roots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'doc' is not defined"
     ]
    }
   ],
   "source": [
    "root = [word for sent in doc.sentences for word in sent.words if word.deprel==\"root\"]\n",
    "print(root)\n",
    "not_roots = [word for sent in doc.sentences for word in sent.words if word.deprel!=\"root\"]\n",
    "print(not_roots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the lemmas for each word\n",
    "print(*[f'word: {word.text+\" \"}\\tlemma: {word.lemma}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 3: Generate other, incorrect answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wrong_answers = random.sample(not_roots, 3)\n",
    "print(wrong_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 4: Put all the potential answers into an array, mix them up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "answers.append(root[0].text)\n",
    "\n",
    "for word in wrong_answers:\n",
    "    answers.append(word.text)\n",
    "    \n",
    "random.shuffle(answers)\n",
    "    \n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 5: Get input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'answers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-f5442717459f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"Not quite\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdemo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"What is the main verb of the sentence:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRadio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'answers' is not defined"
     ]
    }
   ],
   "source": [
    "def check(answer):\n",
    "    if answer == root[0].text:\n",
    "        return \"Correct!\"\n",
    "    return \"Not quite\"\n",
    "\n",
    "demo = gr.Interface(description=\"What is the main verb of the sentence:\", fn=check, inputs=[gr.Radio(answers, label=sentence)], outputs=\"text\")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exercise 2: Accents (identify the word(s) with the impossible accents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: The chosen_words array may vary in length. Ultimately, it would make more sense to have it be a consistent length, even if the number of right/wrong answers changes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 0: Place the words into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ἔδεισεν ', 'δὲ ', 'βοῶπις ', 'πότνια ']\n"
     ]
    }
   ],
   "source": [
    "# define the file name here:\n",
    "word_file = 'lib/words.txt'\n",
    "\n",
    "# list to hold each line of the file\n",
    "all_words = '[]'\n",
    "\n",
    "# Read in the lines from the file\n",
    "with open(word_file) as f:\n",
    "    # create list for holding the exercises\n",
    "    all_words = f.read().splitlines() \n",
    "    \n",
    "print(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 1: Randomly choose x number of words from the list. (These are the words which will be in the question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define x here \n",
    "x = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly generate x number of words\n",
    "chosen_words = random.sample(all_words, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 2: Randomly split the array into two parts (correct and incorrect answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['πότνια ', 'ἔδεισεν ', 'δὲ ', 'βοῶπις ']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "divider = random.randint(0, x)\n",
    "correct_words = chosen_words[:divider]\n",
    "incorrect_words = chosen_words[divider:]\n",
    "\n",
    "print(incorrect_words)\n",
    "print(correct_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 3: For each 'incorrect' word,\n",
    "    1. make a list of all the potentially correct accentuations\n",
    "    2. strip the accents\n",
    "    3. randomly insert accents\n",
    "    4. check whether the accents are valid (whether they're in the list)\n",
    "    5. try to replace the word with a version containing invalid accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ποτνιά ', 'ποτνιᾶ ', 'ποτνία ', 'ποτνῖα ', 'πότνια ']\n",
      "['ποτνιά ', 'ποτνιᾶ ', 'ποτνία ', 'ποτνῖα ', 'πότνια ']\n",
      "['ἐδεισέν ', 'ἐδεῖσεν ', 'ἔδεισεν ']\n",
      "['ἐδεισέν ', 'ἐδεισε͂ν ', 'ἐδείσεν ', 'ἐδεῖσεν ', 'ἔδεισεν ']\n",
      "['δέ ']\n",
      "['δέ ', 'δε͂ ']\n",
      "['βοωπίς ', 'βοωπῖς ', 'βοώπις ', 'βοῶπις ', 'βόωπις ']\n",
      "['βοωπίς ', 'βοωπῖς ', 'βοώπις ', 'βοῶπις ', 'βόωπις ']\n",
      "['ἐδείσεν ', 'δε͂ ']\n"
     ]
    }
   ],
   "source": [
    "to_remove = []\n",
    "\n",
    "# loop through each of the words for which we will assign incorrect accents\n",
    "for w_index in range(0, len(incorrect_words)):\n",
    "    \n",
    "    # get the word, break it into syllables\n",
    "    w = incorrect_words[w_index]\n",
    "    s = syllabify(strip_accents(w))\n",
    "    \n",
    "    # types of accents\n",
    "    types = [Accentuation.OXYTONE, Accentuation.PERISPOMENON, Accentuation.PAROXYTONE, Accentuation.PROPERISPOMENON, Accentuation.PROPAROXYTONE]\n",
    "    \n",
    "    # make a list of *potentially correct* accentuations for that word\n",
    "    possible_correct = []\n",
    "    for a in possible_accentuations(s):\n",
    "        possible_correct.append(add_accentuation(s, a))\n",
    "\n",
    "    # make a list of *all* the possible accentuations for that word\n",
    "    all_accents = []\n",
    "    for acc_type in types:\n",
    "        try:\n",
    "            all_accents.append(add_accentuation(s, acc_type))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # find the difference between the two lists\n",
    "    possible_incorrect = list(set(all_accents)-set(possible_correct))\n",
    "    \n",
    "    # if there are no incorrect answers, remove the word from incorrect_words\n",
    "    if len(possible_incorrect) == 0:\n",
    "        to_remove.append(w)\n",
    "        \n",
    "    # if there is an incorrect answer, add it to the list\n",
    "    elif len(possible_incorrect) == 0:\n",
    "        incorrect_words[w_index] = possible_incorrect[0]\n",
    "        \n",
    "    # if there is ore than one incorrect answer, randomly pick one\n",
    "    else:\n",
    "        incorrect_words[w_index] = random.choice(possible_incorrect)\n",
    "    \n",
    "    print(possible_correct)\n",
    "    print(all_accents)\n",
    "\n",
    "for r in to_remove:\n",
    "    incorrect_words.remove(r)\n",
    "    \n",
    "print(incorrect_words)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 4: shuffle the array of answers (both correct and incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinsert the incorrect answers into the original array\n",
    "chosen_words = correct_words[:] + incorrect_words[:]\n",
    "\n",
    "# shuffle the array\n",
    "random.shuffle(chosen_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Step 5: Get input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ἐδείσεν ', 'δε͂ ']\n",
      "Running on local URL:  http://127.0.0.1:7897/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7897/\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x7fa9b167e7c0>, 'http://127.0.0.1:7897/', None)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback None(<Task finishe...> result=None>)\n",
      "handle: <Handle>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "TypeError: 'NoneType' object is not callable\n"
     ]
    }
   ],
   "source": [
    "def check2(answer):\n",
    "    if not len(answer) == len(incorrect_words):\n",
    "        return \"You have either selected too many or too few answers\"\n",
    "        \n",
    "    for i in answer:\n",
    "        if i not in incorrect_words:\n",
    "            return \"One or more of your answers is incorrect\"\n",
    "        \n",
    "    return \"Correct!\"\n",
    "\n",
    "demo2 = gr.Interface(description=\"Which of the following words contain impossible accents?:\", fn=check2, inputs=[gr.CheckboxGroup(choices=chosen_words, type=\"value\")], outputs=\"text\")\n",
    "\n",
    "demo2.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
